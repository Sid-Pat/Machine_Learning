{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1>1. Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to apply Linear Regression\n",
    "def LinearRegressionFunc(x_train, y_train, x_test, y_test):\n",
    "    # Create a Linear Regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate RMSE, MAE, and R2 score\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred)) # Root Mean Square Error\n",
    "    mae = mean_absolute_error(y_test, y_pred) # Mean Absolute Error\n",
    "    r2 = r2_score(y_test, y_pred) # R2 Score\n",
    "    return rmse, mae, r2\n",
    "\n",
    "# Example usage:\n",
    "# rmse, mae, r2 = LinearRegressionFunc(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes-5-fold\n",
      "RMSE : 0.6275034933741999\n",
      "MAE : 0.494077207332955\n",
      "r2_score : -0.02270533734305826\n",
      "\n",
      "machineCPU-5-fold\n",
      "RMSE : 63.38092966076756\n",
      "MAE : 40.08550007555207\n",
      "r2_score : 0.827429222855281\n",
      "\n",
      "mortgage-5-fold\n",
      "RMSE : 0.12113615984788388\n",
      "MAE : 0.08349366703499722\n",
      "r2_score : 0.9984080525234482\n",
      "\n",
      "plastic-5-fold\n",
      "RMSE : 1.530470905327664\n",
      "MAE : 1.2324659378443346\n",
      "r2_score : 0.798323981892727\n",
      "\n",
      "stock-5-fold\n",
      "RMSE : 2.347664630867212\n",
      "MAE : 1.838093466586368\n",
      "r2_score : 0.870132731760774\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#global map for storing results of each dataset separately\n",
    "gl_map = {}  # Key type = {dataset,degree,alpha}\n",
    "\n",
    "#All datasets used:\n",
    "folders = [\"diabetes-5-fold\",\"machineCPU-5-fold\",\"mortgage-5-fold\",\"plastic-5-fold\",\"stock-5-fold\"]\n",
    "\n",
    "#Loop structure \n",
    "\n",
    "# loop-1(dataset)\n",
    "#            |-> loop-2(files)\n",
    "\n",
    "#Double nested loops \n",
    "# 1. On folder/directory\n",
    "        # 2.On each folder's five files (train and test)\n",
    "\n",
    "#loop-1\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    # Define the file pattern\n",
    "    file_pattern = \"*tra.dat\"  # Matches files with the pattern diabetes-5-*tra.dat\n",
    "    # Use glob to find files that match the pattern\n",
    "    training_files = glob.glob(\"./\"+folder+\"/\"+file_pattern)\n",
    "    #same for test files\n",
    "    file_pattern = \"*tst.dat\"  # Matches files with the pattern diabetes-5-*-tra.dat\n",
    "    testing_files = glob.glob(\"./\"+folder+\"/\"+file_pattern)\n",
    "    \n",
    "    trmse = 0 #total of rmse\n",
    "    tmae = 0 #total of mae\n",
    "    tr2 = 0 #total of r2 score\n",
    "    #loop-2\n",
    "    for train_file,test_file in zip(training_files, testing_files): #zip reads both at the same time\n",
    "        # delimiter = comma (as .dat file) and comment the lines start with '@' (as only info of file)  \n",
    "        df = pd.read_csv(train_file,delimiter=',', header=None, comment='@')\n",
    "        df_test = pd.read_csv(test_file, delimiter=',', header=None, comment='@')\n",
    "        x_train = df.iloc[:,:-1]\n",
    "        y_train = df.iloc[:,-1]\n",
    "        x_test = df_test.iloc[:,:-1]\n",
    "        y_test = df_test.iloc[:,-1]\n",
    "        # Helper Linear Regression Function\n",
    "        rmse, mae, r2 = LinearRegressionFunc(x_train,y_train,x_test,y_test)\n",
    "        # print(r2)\n",
    "        trmse+=rmse\n",
    "        tmae+=mae\n",
    "        tr2+=r2\n",
    "    # Taking average of all 5 datasets for a particular folder\n",
    "    trmse/=5\n",
    "    tmae/=5\n",
    "    tr2/=5\n",
    "    # Putting the value in the map\n",
    "    gl_map[(folder,1,0)] = (tmae,trmse,tr2) #dataset=current one, degree=1 (Linear Regression) and alpha = 0\n",
    "    # alpha = hyperparameter\n",
    "    print(f\"RMSE : {trmse}\\nMAE : {tmae}\\nr2_score : {tr2}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1>2. Polynomial Regression   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to apply Polynomial Regression and return mae, rmse, r2\n",
    "def PolynomialRegressionFunc(x_train, y_train, x_test, y_test, degree):\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly.fit_transform(x_train)\n",
    "    x_test_poly = poly.transform(x_test)\n",
    "\n",
    "    # Applying Linear Regression on updated features after Polynomial Features fitting \n",
    "    # Create a Linear Regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model on the polynomial features\n",
    "    model.fit(x_train_poly, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(x_test_poly)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# Example usage:\n",
    "# mae, rmse, r2 = PolynomialRegressionFunc(x_train, y_train, x_test, y_test, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes-5-fold\n",
      "degree : 1\n",
      "RMSE : 0.6275034933742001\n",
      "MAE : 0.4940772073329551\n",
      "r2_score : -0.02270533734305884\n",
      "\n",
      "degree : 2\n",
      "RMSE : 0.5472957597225531\n",
      "MAE : 0.45727247144417477\n",
      "r2_score : 0.23037469891948786\n",
      "\n",
      "degree : 3\n",
      "RMSE : 1.0181883870263977\n",
      "MAE : 0.7174549374896216\n",
      "r2_score : -2.3483537333744224\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "machineCPU-5-fold\n",
      "degree : 1\n",
      "RMSE : 63.38092966076749\n",
      "MAE : 40.08550007555239\n",
      "r2_score : 0.827429222855281\n",
      "\n",
      "degree : 2\n",
      "RMSE : 111.6321957099212\n",
      "MAE : 56.47223787750264\n",
      "r2_score : 0.4169487114312546\n",
      "\n",
      "degree : 3\n",
      "RMSE : 425.71229045611517\n",
      "MAE : 138.90750914948543\n",
      "r2_score : -9.570435624190653\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "mortgage-5-fold\n",
      "degree : 1\n",
      "RMSE : 0.12113615984788387\n",
      "MAE : 0.08349366703499836\n",
      "r2_score : 0.9984080525234482\n",
      "\n",
      "degree : 2\n",
      "RMSE : 0.10820761705200665\n",
      "MAE : 0.05575064547471574\n",
      "r2_score : 0.9985365673712003\n",
      "\n",
      "degree : 3\n",
      "RMSE : 2.307535884390398\n",
      "MAE : 0.499848937630815\n",
      "r2_score : 0.1416365652878219\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "plastic-5-fold\n",
      "degree : 1\n",
      "RMSE : 1.5304709053276633\n",
      "MAE : 1.2324659378443308\n",
      "r2_score : 0.798323981892727\n",
      "\n",
      "degree : 2\n",
      "RMSE : 1.5268559938669388\n",
      "MAE : 1.225784432297814\n",
      "r2_score : 0.7992571503504685\n",
      "\n",
      "degree : 3\n",
      "RMSE : 1.47195993916684\n",
      "MAE : 1.165697208021562\n",
      "r2_score : 0.8132586190836044\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "stock-5-fold\n",
      "degree : 1\n",
      "RMSE : 2.347664630867213\n",
      "MAE : 1.8380934665863684\n",
      "r2_score : 0.8701327317607739\n",
      "\n",
      "degree : 2\n",
      "RMSE : 1.1249389285638103\n",
      "MAE : 0.9008366499871746\n",
      "r2_score : 0.9702033012145972\n",
      "\n",
      "degree : 3\n",
      "RMSE : 0.8897448103226854\n",
      "MAE : 0.6709120745559728\n",
      "r2_score : 0.9812735607457554\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Taking all datasets in a folders for iterating\n",
    "folders = [\"diabetes-5-fold\",\"machineCPU-5-fold\",\"mortgage-5-fold\",\"plastic-5-fold\",\"stock-5-fold\"]\n",
    "\n",
    "#Loop structure \n",
    "\n",
    "# loop-1(dataset)\n",
    "#            |-> loop-2(degree)\n",
    "#                         |-> loop-3(files)\n",
    "\n",
    "# loop-1 on datasets\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    # File pattern matching\n",
    "    # Define the file pattern\n",
    "    file_pattern = \"*tra.dat\"  # Matches files with the pattern diabetes-5-*tra.dat\n",
    "    # Use glob to find files that match the pattern\n",
    "    training_files = glob.glob(\"./\"+folder+\"/\"+file_pattern)\n",
    "    file_pattern = \"*tst.dat\"  # Matches files with the pattern diabetes-5-*-tra.dat\n",
    "    testing_files = glob.glob(\"./\"+folder+\"/\"+file_pattern)\n",
    "    \n",
    "    # loop-2 on degree\n",
    "    degree = [1,2,3]\n",
    "    for d in degree:\n",
    "        trmse = 0 \n",
    "        tmae = 0\n",
    "        tr2 = 0\n",
    "        # loop-3 on training and testing files:\n",
    "        for train_file,test_file in zip(training_files, testing_files):\n",
    "            #reading train and test files as dataframes\n",
    "            df = pd.read_csv(train_file,delimiter=',', header=None, comment='@')\n",
    "            df_test = pd.read_csv(test_file, delimiter=',', header=None, comment='@')\n",
    "            #first n-1 as features and last one as target \n",
    "            x_train = df.iloc[:,:-1]\n",
    "            y_train = df.iloc[:,-1]\n",
    "            x_test = df_test.iloc[:,:-1]\n",
    "            y_test = df_test.iloc[:,-1]\n",
    "            mae, rmse, r2 = PolynomialRegressionFunc(x_train,y_train,x_test,y_test,d)\n",
    "            #Taking sum for a particular folder\n",
    "            trmse+=rmse\n",
    "            tmae+=mae\n",
    "            tr2+=r2\n",
    "        #Taking average for a particular folder\n",
    "        trmse/=5\n",
    "        tmae/=5\n",
    "        tr2/=5\n",
    "        print(f\"degree : {d}\")\n",
    "        # print(f\"{folder}:\\n\")\n",
    "        gl_map[(folder,d,0)] = (tmae,trmse,tr2)\n",
    "        print(f\"RMSE : {trmse}\\nMAE : {tmae}\\nr2_score : {tr2}\\n\") \n",
    "    #Used as separator\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1>3. Ridge Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpha \n",
    "###### very high => Underfitting\n",
    "###### medium => Perfect \n",
    "###### Very low => Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to apply Polynomial Ridge Regularization and return rmse, mae, r2:\n",
    "def PolynomialRidgeRegressionMetrics(x_train, y_train, x_test, y_test, degree, alpha):\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    x_train_poly = poly.fit_transform(x_train)\n",
    "    x_test_poly = poly.transform(x_test)\n",
    "\n",
    "    \n",
    "    # Create a Ridge Regression model\n",
    "    model = Ridge(alpha=alpha)\n",
    "\n",
    "    # Fit the model on the polynomial features\n",
    "    model.fit(x_train_poly, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(x_test_poly)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return rmse, mae, r2\n",
    "\n",
    "# Example usage:\n",
    "# mae, rmse, r2 = PolynomialRegressionMetrics(x_train, y_train, x_test, y_test, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes-5-fold\n",
      "machineCPU-5-fold\n",
      "mortgage-5-fold\n",
      "plastic-5-fold\n",
      "stock-5-fold\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#Loop structure \n",
    "\n",
    "# loop-1(dataset)\n",
    "#            |-> loop-2(degree)\n",
    "#                         |-> loop-3(alpha)\n",
    "#                                     |-> loop-4(trainging and testing files)\n",
    "ans_map = {}\n",
    "folders = [\"diabetes-5-fold\",\"machineCPU-5-fold\",\"mortgage-5-fold\",\"plastic-5-fold\",\"stock-5-fold\"]\n",
    "#loop-1 (datasets)\n",
    "for folder in folders:\n",
    "    print(folder)\n",
    "    # Define the file pattern\n",
    "    file_pattern = \"*tra.dat\"  # Matches files with the pattern diabetes-5-*tra.dat\n",
    "    # Use glob to find files that match the pattern\n",
    "    training_files = glob.glob(\"./\"+folder+\"/\"+file_pattern)\n",
    "    file_pattern = \"*tst.dat\"  # Matches files with the pattern diabetes-5-*-tra.dat\n",
    "    testing_files = glob.glob(\"./\"+folder+\"/\"+file_pattern)\n",
    "    \n",
    "    #Storing alpha values from 2^(-18),2^(-16),2^(-14), .... , 2^(50)\n",
    "    alpha_values = [2**i for i in range(-18,51,2)]\n",
    "    degree = [2,3]\n",
    "    #loop-2 (degree)\n",
    "    for d in degree:\n",
    "        gl_map = {}\n",
    "        #loop-3 (alpha value)\n",
    "        for alpha in alpha_values:\n",
    "            trmse = 0 \n",
    "            tmae = 0\n",
    "            tr2 = 0\n",
    "            #loop-4 (training and testing files in datasets)\n",
    "            for train_file,test_file in zip(training_files, testing_files):\n",
    "                df = pd.read_csv(train_file,delimiter=',', header=None, comment='@')\n",
    "                df_test = pd.read_csv(test_file, delimiter=',', header=None, comment='@')\n",
    "                # print(df)\n",
    "                x_train = df.iloc[:,:-1]\n",
    "                y_train = df.iloc[:,-1]\n",
    "                x_test = df_test.iloc[:,:-1]\n",
    "                y_test = df_test.iloc[:,-1]\n",
    "                rmse, mae, r2 = PolynomialRidgeRegressionMetrics(x_train,y_train,x_test,y_test,d,alpha)\n",
    "                # print(r2)\n",
    "                trmse+=rmse\n",
    "                tmae+=mae\n",
    "                tr2+=r2\n",
    "            trmse/=5\n",
    "            tmae/=5\n",
    "            tr2/=5\n",
    "            ans_map[(folder,d,alpha)] = (trmse,tmae,tr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree: 2.0000, Alpha: 0.00000381, RMSE: 0.5473, MAE: 0.4573, R2: 0.2304\n",
      "Degree: 2.0000, Alpha: 0.00001526, RMSE: 0.5473, MAE: 0.4573, R2: 0.2304\n",
      "Degree: 2.0000, Alpha: 0.00006104, RMSE: 0.5473, MAE: 0.4573, R2: 0.2304\n",
      "Degree: 2.0000, Alpha: 0.00024414, RMSE: 0.5473, MAE: 0.4573, R2: 0.2304\n",
      "Degree: 2.0000, Alpha: 0.00097656, RMSE: 0.5473, MAE: 0.4573, R2: 0.2304\n",
      "Degree: 2.0000, Alpha: 0.00390625, RMSE: 0.5473, MAE: 0.4573, R2: 0.2304\n",
      "Degree: 2.0000, Alpha: 0.01562500, RMSE: 0.5472, MAE: 0.4572, R2: 0.2305\n",
      "Degree: 2.0000, Alpha: 0.06250000, RMSE: 0.5470, MAE: 0.4571, R2: 0.2308\n",
      "Degree: 2.0000, Alpha: 0.25000000, RMSE: 0.5461, MAE: 0.4566, R2: 0.2320\n",
      "Degree: 2.0000, Alpha: 1.00000000, RMSE: 0.5438, MAE: 0.4547, R2: 0.2349\n",
      "Degree: 2.0000, Alpha: 4.00000000, RMSE: 0.5434, MAE: 0.4498, R2: 0.2302\n",
      "Degree: 2.0000, Alpha: 16.00000000, RMSE: 0.5636, MAE: 0.4565, R2: 0.1821\n",
      "Degree: 2.0000, Alpha: 64.00000000, RMSE: 0.6092, MAE: 0.4929, R2: 0.0691\n",
      "Degree: 2.0000, Alpha: 256.00000000, RMSE: 0.6721, MAE: 0.5340, R2: -0.1206\n",
      "Degree: 2.0000, Alpha: 1024.00000000, RMSE: 0.7122, MAE: 0.5623, R2: -0.2584\n",
      "Degree: 2.0000, Alpha: 4096.00000000, RMSE: 0.7249, MAE: 0.5711, R2: -0.3035\n",
      "Degree: 2.0000, Alpha: 16384.00000000, RMSE: 0.7240, MAE: 0.5707, R2: -0.2954\n",
      "Degree: 2.0000, Alpha: 65536.00000000, RMSE: 0.7158, MAE: 0.5636, R2: -0.2451\n",
      "Degree: 2.0000, Alpha: 262144.00000000, RMSE: 0.7006, MAE: 0.5517, R2: -0.1545\n",
      "Degree: 2.0000, Alpha: 1048576.00000000, RMSE: 0.6915, MAE: 0.5436, R2: -0.1010\n",
      "Degree: 2.0000, Alpha: 4194304.00000000, RMSE: 0.7037, MAE: 0.5497, R2: -0.1354\n",
      "Degree: 2.0000, Alpha: 16777216.00000000, RMSE: 0.7147, MAE: 0.5557, R2: -0.1709\n",
      "Degree: 2.0000, Alpha: 67108864.00000000, RMSE: 0.7186, MAE: 0.5577, R2: -0.1838\n",
      "Degree: 2.0000, Alpha: 268435456.00000000, RMSE: 0.7197, MAE: 0.5582, R2: -0.1874\n",
      "Degree: 2.0000, Alpha: 1073741824.00000000, RMSE: 0.7200, MAE: 0.5584, R2: -0.1883\n",
      "Degree: 2.0000, Alpha: 4294967296.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1885\n",
      "Degree: 2.0000, Alpha: 17179869184.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 2.0000, Alpha: 68719476736.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 2.0000, Alpha: 274877906944.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 2.0000, Alpha: 1099511627776.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 2.0000, Alpha: 4398046511104.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 2.0000, Alpha: 17592186044416.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 2.0000, Alpha: 70368744177664.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 2.0000, Alpha: 281474976710656.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 2.0000, Alpha: 1125899906842624.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 3.0000, Alpha: 0.00000381, RMSE: 1.0182, MAE: 0.7175, R2: -2.3483\n",
      "Degree: 3.0000, Alpha: 0.00001526, RMSE: 1.0182, MAE: 0.7174, R2: -2.3481\n",
      "Degree: 3.0000, Alpha: 0.00006104, RMSE: 1.0181, MAE: 0.7174, R2: -2.3473\n",
      "Degree: 3.0000, Alpha: 0.00024414, RMSE: 1.0178, MAE: 0.7172, R2: -2.3443\n",
      "Degree: 3.0000, Alpha: 0.00097656, RMSE: 1.0166, MAE: 0.7166, R2: -2.3321\n",
      "Degree: 3.0000, Alpha: 0.00390625, RMSE: 1.0121, MAE: 0.7141, R2: -2.2843\n",
      "Degree: 3.0000, Alpha: 0.01562500, RMSE: 0.9948, MAE: 0.7047, R2: -2.1081\n",
      "Degree: 3.0000, Alpha: 0.06250000, RMSE: 0.9386, MAE: 0.6735, R2: -1.5822\n",
      "Degree: 3.0000, Alpha: 0.25000000, RMSE: 0.8193, MAE: 0.6033, R2: -0.7050\n",
      "Degree: 3.0000, Alpha: 1.00000000, RMSE: 0.7066, MAE: 0.5387, R2: -0.1664\n",
      "Degree: 3.0000, Alpha: 4.00000000, RMSE: 0.6984, MAE: 0.5459, R2: -0.1415\n",
      "Degree: 3.0000, Alpha: 16.00000000, RMSE: 0.7686, MAE: 0.5936, R2: -0.4555\n",
      "Degree: 3.0000, Alpha: 64.00000000, RMSE: 0.8125, MAE: 0.6183, R2: -0.7179\n",
      "Degree: 3.0000, Alpha: 256.00000000, RMSE: 0.8120, MAE: 0.6161, R2: -0.7351\n",
      "Degree: 3.0000, Alpha: 1024.00000000, RMSE: 0.7929, MAE: 0.6046, R2: -0.6549\n",
      "Degree: 3.0000, Alpha: 4096.00000000, RMSE: 0.7771, MAE: 0.5974, R2: -0.5726\n",
      "Degree: 3.0000, Alpha: 16384.00000000, RMSE: 0.7312, MAE: 0.5852, R2: -0.3031\n",
      "Degree: 3.0000, Alpha: 65536.00000000, RMSE: 0.6940, MAE: 0.5619, R2: -0.1400\n",
      "Degree: 3.0000, Alpha: 262144.00000000, RMSE: 0.6880, MAE: 0.5621, R2: -0.1266\n",
      "Degree: 3.0000, Alpha: 1048576.00000000, RMSE: 0.7179, MAE: 0.5748, R2: -0.2431\n",
      "Degree: 3.0000, Alpha: 4194304.00000000, RMSE: 0.7718, MAE: 0.6079, R2: -0.4484\n",
      "Degree: 3.0000, Alpha: 16777216.00000000, RMSE: 0.7870, MAE: 0.6121, R2: -0.4985\n",
      "Degree: 3.0000, Alpha: 67108864.00000000, RMSE: 0.7666, MAE: 0.5935, R2: -0.3931\n",
      "Degree: 3.0000, Alpha: 268435456.00000000, RMSE: 0.7297, MAE: 0.5689, R2: -0.2298\n",
      "Degree: 3.0000, Alpha: 1073741824.00000000, RMSE: 0.7113, MAE: 0.5573, R2: -0.1592\n",
      "Degree: 3.0000, Alpha: 4294967296.00000000, RMSE: 0.7148, MAE: 0.5569, R2: -0.1708\n",
      "Degree: 3.0000, Alpha: 17179869184.00000000, RMSE: 0.7184, MAE: 0.5579, R2: -0.1830\n",
      "Degree: 3.0000, Alpha: 68719476736.00000000, RMSE: 0.7197, MAE: 0.5583, R2: -0.1871\n",
      "Degree: 3.0000, Alpha: 274877906944.00000000, RMSE: 0.7200, MAE: 0.5584, R2: -0.1882\n",
      "Degree: 3.0000, Alpha: 1099511627776.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1885\n",
      "Degree: 3.0000, Alpha: 4398046511104.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 3.0000, Alpha: 17592186044416.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 3.0000, Alpha: 70368744177664.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 3.0000, Alpha: 281474976710656.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 3.0000, Alpha: 1125899906842624.00000000, RMSE: 0.7201, MAE: 0.5584, R2: -0.1886\n",
      "Degree: 2.0000, Alpha: 0.00000381, RMSE: 65.7024, MAE: 35.5100, R2: 0.8266\n",
      "Degree: 2.0000, Alpha: 0.00001526, RMSE: 65.7024, MAE: 35.5100, R2: 0.8266\n",
      "Degree: 2.0000, Alpha: 0.00006104, RMSE: 65.7024, MAE: 35.5100, R2: 0.8266\n",
      "Degree: 2.0000, Alpha: 0.00024414, RMSE: 65.7024, MAE: 35.5100, R2: 0.8266\n",
      "Degree: 2.0000, Alpha: 0.00097656, RMSE: 65.7024, MAE: 35.5100, R2: 0.8266\n",
      "Degree: 2.0000, Alpha: 0.00390625, RMSE: 65.7024, MAE: 35.5100, R2: 0.8266\n",
      "Degree: 2.0000, Alpha: 0.01562500, RMSE: 65.7023, MAE: 35.5100, R2: 0.8266\n",
      "Degree: 2.0000, Alpha: 0.06250000, RMSE: 65.7017, MAE: 35.5099, R2: 0.8266\n",
      "Degree: 2.0000, Alpha: 0.25000000, RMSE: 65.6996, MAE: 35.5094, R2: 0.8266\n",
      "Degree: 2.0000, Alpha: 1.00000000, RMSE: 65.6911, MAE: 35.5073, R2: 0.8267\n",
      "Degree: 2.0000, Alpha: 4.00000000, RMSE: 65.6584, MAE: 35.4997, R2: 0.8269\n",
      "Degree: 2.0000, Alpha: 16.00000000, RMSE: 65.5469, MAE: 35.4749, R2: 0.8276\n",
      "Degree: 2.0000, Alpha: 64.00000000, RMSE: 65.2923, MAE: 35.4155, R2: 0.8291\n",
      "Degree: 2.0000, Alpha: 256.00000000, RMSE: 65.1599, MAE: 35.3755, R2: 0.8300\n",
      "Degree: 2.0000, Alpha: 1024.00000000, RMSE: 65.8708, MAE: 35.5261, R2: 0.8265\n",
      "Degree: 2.0000, Alpha: 4096.00000000, RMSE: 68.0809, MAE: 35.9347, R2: 0.8149\n",
      "Degree: 2.0000, Alpha: 16384.00000000, RMSE: 71.3101, MAE: 36.3803, R2: 0.7962\n",
      "Degree: 2.0000, Alpha: 65536.00000000, RMSE: 73.4149, MAE: 36.5326, R2: 0.7831\n",
      "Degree: 2.0000, Alpha: 262144.00000000, RMSE: 73.9374, MAE: 36.2035, R2: 0.7805\n",
      "Degree: 2.0000, Alpha: 1048576.00000000, RMSE: 73.8776, MAE: 35.1400, R2: 0.7826\n",
      "Degree: 2.0000, Alpha: 4194304.00000000, RMSE: 73.7292, MAE: 33.6929, R2: 0.7835\n",
      "Degree: 2.0000, Alpha: 16777216.00000000, RMSE: 73.1354, MAE: 32.7369, R2: 0.7863\n",
      "Degree: 2.0000, Alpha: 67108864.00000000, RMSE: 71.5174, MAE: 32.2061, R2: 0.7962\n",
      "Degree: 2.0000, Alpha: 268435456.00000000, RMSE: 66.6800, MAE: 30.9631, R2: 0.8244\n",
      "Degree: 2.0000, Alpha: 1073741824.00000000, RMSE: 59.0238, MAE: 28.9208, R2: 0.8586\n",
      "Degree: 2.0000, Alpha: 4294967296.00000000, RMSE: 56.1649, MAE: 28.3617, R2: 0.8646\n",
      "Degree: 2.0000, Alpha: 17179869184.00000000, RMSE: 56.3414, MAE: 29.1104, R2: 0.8620\n",
      "Degree: 2.0000, Alpha: 68719476736.00000000, RMSE: 55.8029, MAE: 29.7973, R2: 0.8646\n",
      "Degree: 2.0000, Alpha: 274877906944.00000000, RMSE: 54.9389, MAE: 30.4260, R2: 0.8686\n",
      "Degree: 2.0000, Alpha: 1099511627776.00000000, RMSE: 54.6208, MAE: 30.9912, R2: 0.8693\n",
      "Degree: 2.0000, Alpha: 4398046511104.00000000, RMSE: 54.5544, MAE: 31.4532, R2: 0.8694\n",
      "Degree: 2.0000, Alpha: 17592186044416.00000000, RMSE: 55.8639, MAE: 32.4939, R2: 0.8640\n",
      "Degree: 2.0000, Alpha: 70368744177664.00000000, RMSE: 62.1177, MAE: 34.8868, R2: 0.8302\n",
      "Degree: 2.0000, Alpha: 281474976710656.00000000, RMSE: 71.1729, MAE: 38.0591, R2: 0.7715\n",
      "Degree: 2.0000, Alpha: 1125899906842624.00000000, RMSE: 76.1341, MAE: 40.0400, R2: 0.7352\n",
      "Degree: 3.0000, Alpha: 0.00000381, RMSE: 854.7395, MAE: 210.9556, R2: -49.0130\n",
      "Degree: 3.0000, Alpha: 0.00001526, RMSE: 854.7394, MAE: 210.9555, R2: -49.0130\n",
      "Degree: 3.0000, Alpha: 0.00006104, RMSE: 854.7390, MAE: 210.9555, R2: -49.0130\n",
      "Degree: 3.0000, Alpha: 0.00024414, RMSE: 854.7372, MAE: 210.9555, R2: -49.0128\n",
      "Degree: 3.0000, Alpha: 0.00097656, RMSE: 854.7300, MAE: 210.9552, R2: -49.0119\n",
      "Degree: 3.0000, Alpha: 0.00390625, RMSE: 854.7013, MAE: 210.9541, R2: -49.0087\n",
      "Degree: 3.0000, Alpha: 0.01562500, RMSE: 854.5873, MAE: 210.9496, R2: -48.9957\n",
      "Degree: 3.0000, Alpha: 0.06250000, RMSE: 854.1448, MAE: 210.9315, R2: -48.9455\n",
      "Degree: 3.0000, Alpha: 0.25000000, RMSE: 852.5610, MAE: 210.8554, R2: -48.7694\n",
      "Degree: 3.0000, Alpha: 1.00000000, RMSE: 848.0802, MAE: 210.5065, R2: -48.3154\n",
      "Degree: 3.0000, Alpha: 4.00000000, RMSE: 839.2697, MAE: 210.2124, R2: -47.7134\n",
      "Degree: 3.0000, Alpha: 16.00000000, RMSE: 827.6734, MAE: 207.2077, R2: -47.4405\n",
      "Degree: 3.0000, Alpha: 64.00000000, RMSE: 823.9500, MAE: 202.3694, R2: -48.0885\n",
      "Degree: 3.0000, Alpha: 256.00000000, RMSE: 830.2914, MAE: 201.7670, R2: -49.7978\n",
      "Degree: 3.0000, Alpha: 1024.00000000, RMSE: 836.0861, MAE: 203.4169, R2: -50.8893\n",
      "Degree: 3.0000, Alpha: 4096.00000000, RMSE: 838.6064, MAE: 203.0533, R2: -51.2097\n",
      "Degree: 3.0000, Alpha: 16384.00000000, RMSE: 839.6547, MAE: 200.0822, R2: -51.2315\n",
      "Degree: 3.0000, Alpha: 65536.00000000, RMSE: 826.1718, MAE: 193.7165, R2: -49.1126\n",
      "Degree: 3.0000, Alpha: 262144.00000000, RMSE: 770.2275, MAE: 182.1369, R2: -42.0243\n",
      "Degree: 3.0000, Alpha: 1048576.00000000, RMSE: 639.6926, MAE: 156.3939, R2: -27.1872\n",
      "Degree: 3.0000, Alpha: 4194304.00000000, RMSE: 458.8987, MAE: 121.2208, R2: -12.0420\n",
      "Degree: 3.0000, Alpha: 16777216.00000000, RMSE: 296.7131, MAE: 88.6485, R2: -4.2783\n",
      "Degree: 3.0000, Alpha: 67108864.00000000, RMSE: 190.2622, MAE: 65.3591, R2: -1.8392\n",
      "Degree: 3.0000, Alpha: 268435456.00000000, RMSE: 216.3767, MAE: 73.2529, R2: -2.1098\n",
      "Degree: 3.0000, Alpha: 1073741824.00000000, RMSE: 235.6762, MAE: 75.8802, R2: -2.3606\n",
      "Degree: 3.0000, Alpha: 4294967296.00000000, RMSE: 233.7498, MAE: 74.5079, R2: -2.2281\n",
      "Degree: 3.0000, Alpha: 17179869184.00000000, RMSE: 227.9115, MAE: 72.6987, R2: -2.0716\n",
      "Degree: 3.0000, Alpha: 68719476736.00000000, RMSE: 227.6864, MAE: 73.0982, R2: -2.0720\n",
      "Degree: 3.0000, Alpha: 274877906944.00000000, RMSE: 228.3417, MAE: 73.4440, R2: -2.1343\n",
      "Degree: 3.0000, Alpha: 1099511627776.00000000, RMSE: 210.0136, MAE: 70.4963, R2: -1.7124\n",
      "Degree: 3.0000, Alpha: 4398046511104.00000000, RMSE: 162.8171, MAE: 60.5802, R2: -0.6951\n",
      "Degree: 3.0000, Alpha: 17592186044416.00000000, RMSE: 114.8931, MAE: 49.1835, R2: 0.1428\n",
      "Degree: 3.0000, Alpha: 70368744177664.00000000, RMSE: 91.7204, MAE: 42.7205, R2: 0.4852\n",
      "Degree: 3.0000, Alpha: 281474976710656.00000000, RMSE: 80.0417, MAE: 39.4018, R2: 0.6473\n",
      "Degree: 3.0000, Alpha: 1125899906842624.00000000, RMSE: 69.1089, MAE: 35.9527, R2: 0.7721\n",
      "Degree: 2.0000, Alpha: 0.00000381, RMSE: 0.1082, MAE: 0.0557, R2: 0.9985\n",
      "Degree: 2.0000, Alpha: 0.00001526, RMSE: 0.1082, MAE: 0.0557, R2: 0.9985\n",
      "Degree: 2.0000, Alpha: 0.00006104, RMSE: 0.1081, MAE: 0.0557, R2: 0.9985\n",
      "Degree: 2.0000, Alpha: 0.00024414, RMSE: 0.1077, MAE: 0.0556, R2: 0.9986\n",
      "Degree: 2.0000, Alpha: 0.00097656, RMSE: 0.1068, MAE: 0.0554, R2: 0.9986\n",
      "Degree: 2.0000, Alpha: 0.00390625, RMSE: 0.1052, MAE: 0.0551, R2: 0.9986\n",
      "Degree: 2.0000, Alpha: 0.01562500, RMSE: 0.1031, MAE: 0.0550, R2: 0.9987\n",
      "Degree: 2.0000, Alpha: 0.06250000, RMSE: 0.0989, MAE: 0.0547, R2: 0.9988\n",
      "Degree: 2.0000, Alpha: 0.25000000, RMSE: 0.0913, MAE: 0.0541, R2: 0.9991\n",
      "Degree: 2.0000, Alpha: 1.00000000, RMSE: 0.0831, MAE: 0.0535, R2: 0.9993\n",
      "Degree: 2.0000, Alpha: 4.00000000, RMSE: 0.0794, MAE: 0.0534, R2: 0.9993\n",
      "Degree: 2.0000, Alpha: 16.00000000, RMSE: 0.0783, MAE: 0.0535, R2: 0.9993\n",
      "Degree: 2.0000, Alpha: 64.00000000, RMSE: 0.0779, MAE: 0.0538, R2: 0.9994\n",
      "Degree: 2.0000, Alpha: 256.00000000, RMSE: 0.0782, MAE: 0.0543, R2: 0.9993\n",
      "Degree: 2.0000, Alpha: 1024.00000000, RMSE: 0.0805, MAE: 0.0559, R2: 0.9993\n",
      "Degree: 2.0000, Alpha: 4096.00000000, RMSE: 0.0840, MAE: 0.0587, R2: 0.9992\n",
      "Degree: 2.0000, Alpha: 16384.00000000, RMSE: 0.0879, MAE: 0.0621, R2: 0.9992\n",
      "Degree: 2.0000, Alpha: 65536.00000000, RMSE: 0.0928, MAE: 0.0662, R2: 0.9991\n",
      "Degree: 2.0000, Alpha: 262144.00000000, RMSE: 0.0970, MAE: 0.0692, R2: 0.9990\n",
      "Degree: 2.0000, Alpha: 1048576.00000000, RMSE: 0.1049, MAE: 0.0751, R2: 0.9988\n",
      "Degree: 2.0000, Alpha: 4194304.00000000, RMSE: 0.1286, MAE: 0.0949, R2: 0.9983\n",
      "Degree: 2.0000, Alpha: 16777216.00000000, RMSE: 0.1764, MAE: 0.1307, R2: 0.9967\n",
      "Degree: 2.0000, Alpha: 67108864.00000000, RMSE: 0.2395, MAE: 0.1765, R2: 0.9939\n",
      "Degree: 2.0000, Alpha: 268435456.00000000, RMSE: 0.3097, MAE: 0.2267, R2: 0.9899\n",
      "Degree: 2.0000, Alpha: 1073741824.00000000, RMSE: 0.3864, MAE: 0.2755, R2: 0.9843\n",
      "Degree: 2.0000, Alpha: 4294967296.00000000, RMSE: 0.4637, MAE: 0.3195, R2: 0.9773\n",
      "Degree: 2.0000, Alpha: 17179869184.00000000, RMSE: 0.5943, MAE: 0.3885, R2: 0.9627\n",
      "Degree: 2.0000, Alpha: 68719476736.00000000, RMSE: 0.8561, MAE: 0.5802, R2: 0.9226\n",
      "Degree: 2.0000, Alpha: 274877906944.00000000, RMSE: 1.1356, MAE: 0.8195, R2: 0.8636\n",
      "Degree: 2.0000, Alpha: 1099511627776.00000000, RMSE: 1.2880, MAE: 0.9514, R2: 0.8245\n",
      "Degree: 2.0000, Alpha: 4398046511104.00000000, RMSE: 1.3609, MAE: 1.0207, R2: 0.8042\n",
      "Degree: 2.0000, Alpha: 17592186044416.00000000, RMSE: 1.4168, MAE: 1.0592, R2: 0.7883\n",
      "Degree: 2.0000, Alpha: 70368744177664.00000000, RMSE: 1.5304, MAE: 1.1418, R2: 0.7536\n",
      "Degree: 2.0000, Alpha: 281474976710656.00000000, RMSE: 1.7589, MAE: 1.3323, R2: 0.6748\n",
      "Degree: 2.0000, Alpha: 1125899906842624.00000000, RMSE: 2.0416, MAE: 1.5476, R2: 0.5614\n",
      "Degree: 3.0000, Alpha: 0.00000381, RMSE: 1.3430, MAE: 0.3049, R2: 0.6955\n",
      "Degree: 3.0000, Alpha: 0.00001526, RMSE: 1.0419, MAE: 0.2563, R2: 0.8286\n",
      "Degree: 3.0000, Alpha: 0.00006104, RMSE: 0.7144, MAE: 0.2057, R2: 0.9334\n",
      "Degree: 3.0000, Alpha: 0.00024414, RMSE: 0.4066, MAE: 0.1611, R2: 0.9808\n",
      "Degree: 3.0000, Alpha: 0.00097656, RMSE: 0.4180, MAE: 0.1427, R2: 0.9789\n",
      "Degree: 3.0000, Alpha: 0.00390625, RMSE: 0.4289, MAE: 0.1301, R2: 0.9733\n",
      "Degree: 3.0000, Alpha: 0.01562500, RMSE: 0.3992, MAE: 0.1195, R2: 0.9769\n",
      "Degree: 3.0000, Alpha: 0.06250000, RMSE: 0.3653, MAE: 0.1092, R2: 0.9806\n",
      "Degree: 3.0000, Alpha: 0.25000000, RMSE: 0.3312, MAE: 0.0983, R2: 0.9831\n",
      "Degree: 3.0000, Alpha: 1.00000000, RMSE: 0.3101, MAE: 0.0904, R2: 0.9843\n",
      "Degree: 3.0000, Alpha: 4.00000000, RMSE: 0.2969, MAE: 0.0857, R2: 0.9859\n",
      "Degree: 3.0000, Alpha: 16.00000000, RMSE: 0.2730, MAE: 0.0832, R2: 0.9890\n",
      "Degree: 3.0000, Alpha: 64.00000000, RMSE: 0.2356, MAE: 0.0778, R2: 0.9926\n",
      "Degree: 3.0000, Alpha: 256.00000000, RMSE: 0.1926, MAE: 0.0705, R2: 0.9955\n",
      "Degree: 3.0000, Alpha: 1024.00000000, RMSE: 0.1520, MAE: 0.0634, R2: 0.9974\n",
      "Degree: 3.0000, Alpha: 4096.00000000, RMSE: 0.1190, MAE: 0.0576, R2: 0.9985\n",
      "Degree: 3.0000, Alpha: 16384.00000000, RMSE: 0.0969, MAE: 0.0524, R2: 0.9990\n",
      "Degree: 3.0000, Alpha: 65536.00000000, RMSE: 0.0873, MAE: 0.0486, R2: 0.9992\n",
      "Degree: 3.0000, Alpha: 262144.00000000, RMSE: 0.0826, MAE: 0.0461, R2: 0.9993\n",
      "Degree: 3.0000, Alpha: 1048576.00000000, RMSE: 0.0787, MAE: 0.0450, R2: 0.9993\n",
      "Degree: 3.0000, Alpha: 4194304.00000000, RMSE: 0.0754, MAE: 0.0447, R2: 0.9994\n",
      "Degree: 3.0000, Alpha: 16777216.00000000, RMSE: 0.0740, MAE: 0.0451, R2: 0.9994\n",
      "Degree: 3.0000, Alpha: 67108864.00000000, RMSE: 0.0743, MAE: 0.0461, R2: 0.9994\n",
      "Degree: 3.0000, Alpha: 268435456.00000000, RMSE: 0.0748, MAE: 0.0476, R2: 0.9994\n",
      "Degree: 3.0000, Alpha: 1073741824.00000000, RMSE: 0.0744, MAE: 0.0487, R2: 0.9994\n",
      "Degree: 3.0000, Alpha: 4294967296.00000000, RMSE: 0.0762, MAE: 0.0510, R2: 0.9994\n",
      "Degree: 3.0000, Alpha: 17179869184.00000000, RMSE: 0.0806, MAE: 0.0551, R2: 0.9993\n",
      "Degree: 3.0000, Alpha: 68719476736.00000000, RMSE: 0.0877, MAE: 0.0616, R2: 0.9992\n",
      "Degree: 3.0000, Alpha: 274877906944.00000000, RMSE: 0.0995, MAE: 0.0707, R2: 0.9989\n",
      "Degree: 3.0000, Alpha: 1099511627776.00000000, RMSE: 0.1142, MAE: 0.0808, R2: 0.9986\n",
      "Degree: 3.0000, Alpha: 4398046511104.00000000, RMSE: 0.1341, MAE: 0.0944, R2: 0.9981\n",
      "Degree: 3.0000, Alpha: 17592186044416.00000000, RMSE: 0.1756, MAE: 0.1263, R2: 0.9968\n",
      "Degree: 3.0000, Alpha: 70368744177664.00000000, RMSE: 0.2544, MAE: 0.1857, R2: 0.9932\n",
      "Degree: 3.0000, Alpha: 281474976710656.00000000, RMSE: 0.3681, MAE: 0.2662, R2: 0.9857\n",
      "Degree: 3.0000, Alpha: 1125899906842624.00000000, RMSE: 0.5258, MAE: 0.3830, R2: 0.9707\n",
      "Degree: 2.0000, Alpha: 0.00000381, RMSE: 1.5269, MAE: 1.2258, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 0.00001526, RMSE: 1.5269, MAE: 1.2258, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 0.00006104, RMSE: 1.5269, MAE: 1.2258, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 0.00024414, RMSE: 1.5269, MAE: 1.2258, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 0.00097656, RMSE: 1.5269, MAE: 1.2258, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 0.00390625, RMSE: 1.5269, MAE: 1.2258, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 0.01562500, RMSE: 1.5269, MAE: 1.2258, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 0.06250000, RMSE: 1.5269, MAE: 1.2258, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 0.25000000, RMSE: 1.5269, MAE: 1.2258, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 1.00000000, RMSE: 1.5268, MAE: 1.2257, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 4.00000000, RMSE: 1.5268, MAE: 1.2256, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 16.00000000, RMSE: 1.5268, MAE: 1.2252, R2: 0.7993\n",
      "Degree: 2.0000, Alpha: 64.00000000, RMSE: 1.5271, MAE: 1.2242, R2: 0.7992\n",
      "Degree: 2.0000, Alpha: 256.00000000, RMSE: 1.5284, MAE: 1.2235, R2: 0.7988\n",
      "Degree: 2.0000, Alpha: 1024.00000000, RMSE: 1.5296, MAE: 1.2235, R2: 0.7985\n",
      "Degree: 2.0000, Alpha: 4096.00000000, RMSE: 1.5296, MAE: 1.2229, R2: 0.7985\n",
      "Degree: 2.0000, Alpha: 16384.00000000, RMSE: 1.5293, MAE: 1.2225, R2: 0.7986\n",
      "Degree: 2.0000, Alpha: 65536.00000000, RMSE: 1.5294, MAE: 1.2234, R2: 0.7986\n",
      "Degree: 2.0000, Alpha: 262144.00000000, RMSE: 1.5326, MAE: 1.2286, R2: 0.7978\n",
      "Degree: 2.0000, Alpha: 1048576.00000000, RMSE: 1.5478, MAE: 1.2462, R2: 0.7937\n",
      "Degree: 2.0000, Alpha: 4194304.00000000, RMSE: 1.5698, MAE: 1.2698, R2: 0.7878\n",
      "Degree: 2.0000, Alpha: 16777216.00000000, RMSE: 1.5819, MAE: 1.2823, R2: 0.7845\n",
      "Degree: 2.0000, Alpha: 67108864.00000000, RMSE: 1.5924, MAE: 1.2928, R2: 0.7817\n",
      "Degree: 2.0000, Alpha: 268435456.00000000, RMSE: 1.6726, MAE: 1.3691, R2: 0.7591\n",
      "Degree: 2.0000, Alpha: 1073741824.00000000, RMSE: 2.1107, MAE: 1.7955, R2: 0.6166\n",
      "Degree: 2.0000, Alpha: 4294967296.00000000, RMSE: 2.8280, MAE: 2.4684, R2: 0.3119\n",
      "Degree: 2.0000, Alpha: 17179869184.00000000, RMSE: 3.2373, MAE: 2.8422, R2: 0.0983\n",
      "Degree: 2.0000, Alpha: 68719476736.00000000, RMSE: 3.3711, MAE: 2.9611, R2: 0.0222\n",
      "Degree: 2.0000, Alpha: 274877906944.00000000, RMSE: 3.4068, MAE: 2.9928, R2: 0.0014\n",
      "Degree: 2.0000, Alpha: 1099511627776.00000000, RMSE: 3.4156, MAE: 3.0009, R2: -0.0038\n",
      "Degree: 2.0000, Alpha: 4398046511104.00000000, RMSE: 3.4177, MAE: 3.0029, R2: -0.0050\n",
      "Degree: 2.0000, Alpha: 17592186044416.00000000, RMSE: 3.4183, MAE: 3.0034, R2: -0.0053\n",
      "Degree: 2.0000, Alpha: 70368744177664.00000000, RMSE: 3.4184, MAE: 3.0035, R2: -0.0054\n",
      "Degree: 2.0000, Alpha: 281474976710656.00000000, RMSE: 3.4184, MAE: 3.0035, R2: -0.0054\n",
      "Degree: 2.0000, Alpha: 1125899906842624.00000000, RMSE: 3.4184, MAE: 3.0036, R2: -0.0054\n",
      "Degree: 3.0000, Alpha: 0.00000381, RMSE: 1.4720, MAE: 1.1657, R2: 0.8133\n",
      "Degree: 3.0000, Alpha: 0.00001526, RMSE: 1.4720, MAE: 1.1657, R2: 0.8133\n",
      "Degree: 3.0000, Alpha: 0.00006104, RMSE: 1.4720, MAE: 1.1657, R2: 0.8133\n",
      "Degree: 3.0000, Alpha: 0.00024414, RMSE: 1.4720, MAE: 1.1657, R2: 0.8133\n",
      "Degree: 3.0000, Alpha: 0.00097656, RMSE: 1.4720, MAE: 1.1657, R2: 0.8133\n",
      "Degree: 3.0000, Alpha: 0.00390625, RMSE: 1.4720, MAE: 1.1657, R2: 0.8133\n",
      "Degree: 3.0000, Alpha: 0.01562500, RMSE: 1.4719, MAE: 1.1655, R2: 0.8133\n",
      "Degree: 3.0000, Alpha: 0.06250000, RMSE: 1.4719, MAE: 1.1652, R2: 0.8133\n",
      "Degree: 3.0000, Alpha: 0.25000000, RMSE: 1.4722, MAE: 1.1646, R2: 0.8132\n",
      "Degree: 3.0000, Alpha: 1.00000000, RMSE: 1.4742, MAE: 1.1660, R2: 0.8127\n",
      "Degree: 3.0000, Alpha: 4.00000000, RMSE: 1.4789, MAE: 1.1716, R2: 0.8115\n",
      "Degree: 3.0000, Alpha: 16.00000000, RMSE: 1.4822, MAE: 1.1760, R2: 0.8107\n",
      "Degree: 3.0000, Alpha: 64.00000000, RMSE: 1.4835, MAE: 1.1778, R2: 0.8104\n",
      "Degree: 3.0000, Alpha: 256.00000000, RMSE: 1.4842, MAE: 1.1781, R2: 0.8102\n",
      "Degree: 3.0000, Alpha: 1024.00000000, RMSE: 1.4862, MAE: 1.1798, R2: 0.8097\n",
      "Degree: 3.0000, Alpha: 4096.00000000, RMSE: 1.4955, MAE: 1.1913, R2: 0.8074\n",
      "Degree: 3.0000, Alpha: 16384.00000000, RMSE: 1.5097, MAE: 1.2072, R2: 0.8037\n",
      "Degree: 3.0000, Alpha: 65536.00000000, RMSE: 1.5175, MAE: 1.2150, R2: 0.8017\n",
      "Degree: 3.0000, Alpha: 262144.00000000, RMSE: 1.5200, MAE: 1.2168, R2: 0.8010\n",
      "Degree: 3.0000, Alpha: 1048576.00000000, RMSE: 1.5214, MAE: 1.2163, R2: 0.8007\n",
      "Degree: 3.0000, Alpha: 4194304.00000000, RMSE: 1.5277, MAE: 1.2190, R2: 0.7990\n",
      "Degree: 3.0000, Alpha: 16777216.00000000, RMSE: 1.5460, MAE: 1.2307, R2: 0.7942\n",
      "Degree: 3.0000, Alpha: 67108864.00000000, RMSE: 1.5622, MAE: 1.2422, R2: 0.7898\n",
      "Degree: 3.0000, Alpha: 268435456.00000000, RMSE: 1.5683, MAE: 1.2471, R2: 0.7882\n",
      "Degree: 3.0000, Alpha: 1073741824.00000000, RMSE: 1.5698, MAE: 1.2488, R2: 0.7878\n",
      "Degree: 3.0000, Alpha: 4294967296.00000000, RMSE: 1.5712, MAE: 1.2517, R2: 0.7874\n",
      "Degree: 3.0000, Alpha: 17179869184.00000000, RMSE: 1.5800, MAE: 1.2647, R2: 0.7851\n",
      "Degree: 3.0000, Alpha: 68719476736.00000000, RMSE: 1.6198, MAE: 1.3087, R2: 0.7741\n",
      "Degree: 3.0000, Alpha: 274877906944.00000000, RMSE: 1.6768, MAE: 1.3653, R2: 0.7579\n",
      "Degree: 3.0000, Alpha: 1099511627776.00000000, RMSE: 1.7070, MAE: 1.3933, R2: 0.7491\n",
      "Degree: 3.0000, Alpha: 4398046511104.00000000, RMSE: 1.7220, MAE: 1.4062, R2: 0.7447\n",
      "Degree: 3.0000, Alpha: 17592186044416.00000000, RMSE: 1.7899, MAE: 1.4684, R2: 0.7241\n",
      "Degree: 3.0000, Alpha: 70368744177664.00000000, RMSE: 2.1727, MAE: 1.8397, R2: 0.5937\n",
      "Degree: 3.0000, Alpha: 281474976710656.00000000, RMSE: 2.8422, MAE: 2.4789, R2: 0.3049\n",
      "Degree: 3.0000, Alpha: 1125899906842624.00000000, RMSE: 3.2397, MAE: 2.8442, R2: 0.0970\n",
      "Degree: 2.0000, Alpha: 0.00000381, RMSE: 1.1249, MAE: 0.9008, R2: 0.9702\n",
      "Degree: 2.0000, Alpha: 0.00001526, RMSE: 1.1249, MAE: 0.9008, R2: 0.9702\n",
      "Degree: 2.0000, Alpha: 0.00006104, RMSE: 1.1249, MAE: 0.9008, R2: 0.9702\n",
      "Degree: 2.0000, Alpha: 0.00024414, RMSE: 1.1249, MAE: 0.9008, R2: 0.9702\n",
      "Degree: 2.0000, Alpha: 0.00097656, RMSE: 1.1249, MAE: 0.9008, R2: 0.9702\n",
      "Degree: 2.0000, Alpha: 0.00390625, RMSE: 1.1249, MAE: 0.9008, R2: 0.9702\n",
      "Degree: 2.0000, Alpha: 0.01562500, RMSE: 1.1247, MAE: 0.9007, R2: 0.9702\n",
      "Degree: 2.0000, Alpha: 0.06250000, RMSE: 1.1240, MAE: 0.9004, R2: 0.9703\n",
      "Degree: 2.0000, Alpha: 0.25000000, RMSE: 1.1219, MAE: 0.8999, R2: 0.9704\n",
      "Degree: 2.0000, Alpha: 1.00000000, RMSE: 1.1190, MAE: 0.8998, R2: 0.9705\n",
      "Degree: 2.0000, Alpha: 4.00000000, RMSE: 1.1192, MAE: 0.9018, R2: 0.9705\n",
      "Degree: 2.0000, Alpha: 16.00000000, RMSE: 1.1258, MAE: 0.9075, R2: 0.9701\n",
      "Degree: 2.0000, Alpha: 64.00000000, RMSE: 1.1466, MAE: 0.9222, R2: 0.9690\n",
      "Degree: 2.0000, Alpha: 256.00000000, RMSE: 1.2100, MAE: 0.9701, R2: 0.9655\n",
      "Degree: 2.0000, Alpha: 1024.00000000, RMSE: 1.2932, MAE: 1.0329, R2: 0.9606\n",
      "Degree: 2.0000, Alpha: 4096.00000000, RMSE: 1.3546, MAE: 1.0814, R2: 0.9568\n",
      "Degree: 2.0000, Alpha: 16384.00000000, RMSE: 1.4246, MAE: 1.1372, R2: 0.9522\n",
      "Degree: 2.0000, Alpha: 65536.00000000, RMSE: 1.5184, MAE: 1.2094, R2: 0.9458\n",
      "Degree: 2.0000, Alpha: 262144.00000000, RMSE: 1.6306, MAE: 1.2943, R2: 0.9375\n",
      "Degree: 2.0000, Alpha: 1048576.00000000, RMSE: 1.7636, MAE: 1.3922, R2: 0.9268\n",
      "Degree: 2.0000, Alpha: 4194304.00000000, RMSE: 1.9424, MAE: 1.5321, R2: 0.9111\n",
      "Degree: 2.0000, Alpha: 16777216.00000000, RMSE: 2.1580, MAE: 1.6889, R2: 0.8902\n",
      "Degree: 2.0000, Alpha: 67108864.00000000, RMSE: 2.3976, MAE: 1.8848, R2: 0.8644\n",
      "Degree: 2.0000, Alpha: 268435456.00000000, RMSE: 2.9366, MAE: 2.4482, R2: 0.7967\n",
      "Degree: 2.0000, Alpha: 1073741824.00000000, RMSE: 4.2027, MAE: 3.6449, R2: 0.5846\n",
      "Degree: 2.0000, Alpha: 4294967296.00000000, RMSE: 5.4592, MAE: 4.6922, R2: 0.2998\n",
      "Degree: 2.0000, Alpha: 17179869184.00000000, RMSE: 6.1432, MAE: 5.1837, R2: 0.1137\n",
      "Degree: 2.0000, Alpha: 68719476736.00000000, RMSE: 6.4212, MAE: 5.3869, R2: 0.0317\n",
      "Degree: 2.0000, Alpha: 274877906944.00000000, RMSE: 6.5087, MAE: 5.4547, R2: 0.0051\n",
      "Degree: 2.0000, Alpha: 1099511627776.00000000, RMSE: 6.5322, MAE: 5.4732, R2: -0.0021\n",
      "Degree: 2.0000, Alpha: 4398046511104.00000000, RMSE: 6.5382, MAE: 5.4779, R2: -0.0039\n",
      "Degree: 2.0000, Alpha: 17592186044416.00000000, RMSE: 6.5398, MAE: 5.4791, R2: -0.0044\n",
      "Degree: 2.0000, Alpha: 70368744177664.00000000, RMSE: 6.5401, MAE: 5.4794, R2: -0.0045\n",
      "Degree: 2.0000, Alpha: 281474976710656.00000000, RMSE: 6.5402, MAE: 5.4795, R2: -0.0045\n",
      "Degree: 2.0000, Alpha: 1125899906842624.00000000, RMSE: 6.5402, MAE: 5.4795, R2: -0.0045\n",
      "Degree: 3.0000, Alpha: 0.00000381, RMSE: 0.8788, MAE: 0.6625, R2: 0.9817\n",
      "Degree: 3.0000, Alpha: 0.00001526, RMSE: 0.8785, MAE: 0.6623, R2: 0.9818\n",
      "Degree: 3.0000, Alpha: 0.00006104, RMSE: 0.8774, MAE: 0.6617, R2: 0.9818\n",
      "Degree: 3.0000, Alpha: 0.00024414, RMSE: 0.8747, MAE: 0.6605, R2: 0.9819\n",
      "Degree: 3.0000, Alpha: 0.00097656, RMSE: 0.8714, MAE: 0.6595, R2: 0.9820\n",
      "Degree: 3.0000, Alpha: 0.00390625, RMSE: 0.8712, MAE: 0.6616, R2: 0.9821\n",
      "Degree: 3.0000, Alpha: 0.01562500, RMSE: 0.8747, MAE: 0.6668, R2: 0.9819\n",
      "Degree: 3.0000, Alpha: 0.06250000, RMSE: 0.8762, MAE: 0.6689, R2: 0.9818\n",
      "Degree: 3.0000, Alpha: 0.25000000, RMSE: 0.8748, MAE: 0.6679, R2: 0.9819\n",
      "Degree: 3.0000, Alpha: 1.00000000, RMSE: 0.8728, MAE: 0.6671, R2: 0.9820\n",
      "Degree: 3.0000, Alpha: 4.00000000, RMSE: 0.8734, MAE: 0.6683, R2: 0.9819\n",
      "Degree: 3.0000, Alpha: 16.00000000, RMSE: 0.8737, MAE: 0.6701, R2: 0.9819\n",
      "Degree: 3.0000, Alpha: 64.00000000, RMSE: 0.8700, MAE: 0.6699, R2: 0.9821\n",
      "Degree: 3.0000, Alpha: 256.00000000, RMSE: 0.8615, MAE: 0.6672, R2: 0.9824\n",
      "Degree: 3.0000, Alpha: 1024.00000000, RMSE: 0.8554, MAE: 0.6642, R2: 0.9827\n",
      "Degree: 3.0000, Alpha: 4096.00000000, RMSE: 0.8591, MAE: 0.6651, R2: 0.9825\n",
      "Degree: 3.0000, Alpha: 16384.00000000, RMSE: 0.8641, MAE: 0.6722, R2: 0.9823\n",
      "Degree: 3.0000, Alpha: 65536.00000000, RMSE: 0.8724, MAE: 0.6815, R2: 0.9820\n",
      "Degree: 3.0000, Alpha: 262144.00000000, RMSE: 0.9029, MAE: 0.7118, R2: 0.9808\n",
      "Degree: 3.0000, Alpha: 1048576.00000000, RMSE: 0.9583, MAE: 0.7639, R2: 0.9784\n",
      "Degree: 3.0000, Alpha: 4194304.00000000, RMSE: 1.0445, MAE: 0.8400, R2: 0.9743\n",
      "Degree: 3.0000, Alpha: 16777216.00000000, RMSE: 1.1420, MAE: 0.9148, R2: 0.9693\n",
      "Degree: 3.0000, Alpha: 67108864.00000000, RMSE: 1.2329, MAE: 0.9848, R2: 0.9642\n",
      "Degree: 3.0000, Alpha: 268435456.00000000, RMSE: 1.3336, MAE: 1.0629, R2: 0.9582\n",
      "Degree: 3.0000, Alpha: 1073741824.00000000, RMSE: 1.4616, MAE: 1.1623, R2: 0.9498\n",
      "Degree: 3.0000, Alpha: 4294967296.00000000, RMSE: 1.6132, MAE: 1.2818, R2: 0.9388\n",
      "Degree: 3.0000, Alpha: 17179869184.00000000, RMSE: 1.7688, MAE: 1.3999, R2: 0.9264\n",
      "Degree: 3.0000, Alpha: 68719476736.00000000, RMSE: 1.9458, MAE: 1.5286, R2: 0.9108\n",
      "Degree: 3.0000, Alpha: 274877906944.00000000, RMSE: 2.1698, MAE: 1.6889, R2: 0.8889\n",
      "Degree: 3.0000, Alpha: 1099511627776.00000000, RMSE: 2.4876, MAE: 1.9625, R2: 0.8540\n",
      "Degree: 3.0000, Alpha: 4398046511104.00000000, RMSE: 3.2431, MAE: 2.7555, R2: 0.7523\n",
      "Degree: 3.0000, Alpha: 17592186044416.00000000, RMSE: 4.6262, MAE: 4.0222, R2: 0.4970\n",
      "Degree: 3.0000, Alpha: 70368744177664.00000000, RMSE: 5.7318, MAE: 4.8990, R2: 0.2283\n",
      "Degree: 3.0000, Alpha: 281474976710656.00000000, RMSE: 6.2644, MAE: 5.2730, R2: 0.0784\n",
      "Degree: 3.0000, Alpha: 1125899906842624.00000000, RMSE: 6.4611, MAE: 5.4175, R2: 0.0196\n"
     ]
    }
   ],
   "source": [
    "# Printing answer from the previous ans_map\n",
    "for key, values in ans_map.items():\n",
    "    datasets, degree, alpha = key\n",
    "    rmse, mae, r2 = values\n",
    "    print(f\"Degree: {degree:.4f}, Alpha: {alpha:.8f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 3.814697265625e-06, RMSE: 1.1612, MAE: 0.9509, R2: 0.5445\n",
      "Alpha: 7.62939453125e-06, RMSE: 1.1612, MAE: 0.9509, R2: 0.5445\n",
      "Alpha: 1.52587890625e-05, RMSE: 1.1612, MAE: 0.9509, R2: 0.5445\n",
      "Alpha: 3.0517578125e-05, RMSE: 1.1612, MAE: 0.9509, R2: 0.5445\n",
      "Alpha: 6.103515625e-05, RMSE: 1.1612, MAE: 0.9509, R2: 0.5445\n",
      "Alpha: 0.0001220703125, RMSE: 1.1612, MAE: 0.9509, R2: 0.5445\n",
      "Alpha: 0.000244140625, RMSE: 1.1612, MAE: 0.9509, R2: 0.5445\n",
      "Alpha: 0.00048828125, RMSE: 1.1612, MAE: 0.9509, R2: 0.5445\n",
      "Alpha: 0.0009765625, RMSE: 1.1612, MAE: 0.9509, R2: 0.5445\n",
      "Alpha: 0.001953125, RMSE: 1.1612, MAE: 0.9509, R2: 0.5445\n",
      "Alpha: 0.00390625, RMSE: 1.1611, MAE: 0.9508, R2: 0.5445\n",
      "Alpha: 0.0078125, RMSE: 1.1611, MAE: 0.9507, R2: 0.5445\n",
      "Alpha: 0.015625, RMSE: 1.1610, MAE: 0.9504, R2: 0.5446\n",
      "Alpha: 0.03125, RMSE: 1.1609, MAE: 0.9498, R2: 0.5447\n",
      "Alpha: 0.0625, RMSE: 1.1607, MAE: 0.9488, R2: 0.5449\n",
      "Alpha: 0.125, RMSE: 1.1602, MAE: 0.9467, R2: 0.5453\n",
      "Alpha: 0.25, RMSE: 1.1594, MAE: 0.9427, R2: 0.5459\n",
      "Alpha: 0.5, RMSE: 1.1585, MAE: 0.9352, R2: 0.5466\n",
      "Alpha: 1, RMSE: 1.1583, MAE: 0.9222, R2: 0.5468\n",
      "Alpha: 2, RMSE: 1.1615, MAE: 0.9016, R2: 0.5443\n",
      "Alpha: 4, RMSE: 1.1730, MAE: 0.8978, R2: 0.5351\n",
      "Alpha: 8, RMSE: 1.1977, MAE: 0.8944, R2: 0.5154\n",
      "Alpha: 16, RMSE: 1.2361, MAE: 0.8906, R2: 0.4838\n",
      "Alpha: 32, RMSE: 1.2850, MAE: 0.9579, R2: 0.4422\n",
      "Alpha: 64, RMSE: 1.3390, MAE: 1.0223, R2: 0.3943\n",
      "Alpha: 128, RMSE: 1.3934, MAE: 1.0797, R2: 0.3441\n",
      "Alpha: 256, RMSE: 1.4447, MAE: 1.1296, R2: 0.2948\n",
      "Alpha: 512, RMSE: 1.4911, MAE: 1.1721, R2: 0.2489\n"
     ]
    }
   ],
   "source": [
    "# Data (Creating data)\n",
    "# Reshape your data using array.reshape(-1, 1) if your data has a single feature\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1) # Converting to column form with one column\n",
    "Y = np.array([3, 4, 2, 5, 7])\n",
    "\n",
    "# Planning :\n",
    "# Consider X now as matrix (We also added column 1 below before calling function)\n",
    "# Dimension of X = Number of data points * 2 (Reason: y = (w1)x + w0)\n",
    "# We are maintaining w1 and w0 in theta \n",
    "\n",
    "# Gradient Descent Function\n",
    "def gradient_descent(X, Y, learning_rate, epochs, alpha=None):\n",
    "    m, n = X.shape\n",
    "    # Making \n",
    "    theta = np.zeros((n, 1))\n",
    "    cost_history = [] # Maintaining cost function value for all iterations (epochs)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        # Hypothesis for calculating Y (Matrix way) Y = X.theta\n",
    "        h = X.dot(theta)\n",
    "\n",
    "        # Error = predicted values - true value \n",
    "        error = h - Y # sum of rediduals\n",
    "\n",
    "        # Regularization term for ridge regression \n",
    "        # if nothing is passed then default value as 0\n",
    "        regularization_term = 0 if alpha is None else alpha * np.sum(theta[1:]**2)\n",
    "        \n",
    "        # Update rule : https://www.youtube.com/watch?v=6v3r9KPM2t0 (watch this to understand this)\n",
    "        #    W(New)  = W(Old) - (learning_rate)*(dJ/dW) \n",
    "        #    Only needs to penalize theta from 1 to above and not 0 (Therefore np.vstack 0  then put all other values)\n",
    "        theta = theta - (learning_rate / m) * (X.T.dot(error) + regularization_term * np.vstack([0, theta[1:]]))\n",
    "        # X.T = Transpose of X\n",
    "        \n",
    "        # Cost function (mean squared error)\n",
    "        cost = np.sum(error**2) / (2 * m) + regularization_term\n",
    "        cost_history.append(cost)\n",
    "\n",
    "    return theta, cost_history\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(X, Y, theta):\n",
    "    h = X.dot(theta) # Predicted Y\n",
    "    rmse = np.sqrt(mean_squared_error(Y, h))\n",
    "    mae = mean_absolute_error(Y, h)\n",
    "    r2 = r2_score(Y, h)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "# Add a column of ones to X for the bias term (after the last column)\n",
    "X_bias = np.c_[np.ones((X.shape[0], 1)), X] # Same number of rows but single column of 1\n",
    "# Set hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "alpha_values = [2**i for i in range(-18,10)]\n",
    "\n",
    "# Perform gradient descent and calculate metrics for different alpha values\n",
    "for alpha in alpha_values:\n",
    "    theta, _ = gradient_descent(X_bias, Y.reshape(-1, 1), learning_rate, epochs, alpha)\n",
    "    rmse, mae, r2 = calculate_metrics(X_bias, Y, theta)\n",
    "    print(f\"Alpha: {alpha}, RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[[0 0]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "# Complex code example to understand their meaning \n",
    "# dot for 2D input is matrix multiplication, not a dot product. What you're seeing is just the result of the normal rules of matrix multiplication. If you want a vector dot product, the easiest way is to use 1D vectors, with no superfluous second dimension:\n",
    "X = np.array([1, 2, 3])\n",
    "THETA = np.array([1, 2, 3])\n",
    "print(X.dot(THETA))\n",
    "# dot-ting two 1D arrays takes a dot product and produces a scalar result.\n",
    "\n",
    "# Stack arrays vertically over each other\n",
    "print(np.vstack([[0,0], THETA[1:]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
